#Config File example
save_dir: workspace/nanodet_m
model:
  weight_averager:
    name: ExpMovingAverager
    decay: 0.9998
  arch:
    name: NanoDetPlus
    detach_epoch: 10
    backbone:
      name: ResNet
      #model_size: 1.0x
      depth: 18
      out_stages: [2, 3, 4]
      activation: LeakyReLU
    fpn:
      name: GhostPAN
      in_channels: [128, 256, 512]
      out_channels: 96
      kernel_size: 5
      num_extra_level: 1
      use_depthwise: True
      activation: LeakyReLU
    head:
      name: NanoDetPlusHead
      num_classes: 10
      input_channel: 96
      feat_channels: 96
      stacked_convs: 2
      kernel_size: 5
      strides: [8, 16, 32, 64]
      activation: LeakyReLU
      reg_max: 7
      norm_cfg:
        type: BN
      loss:
        loss_qfl:
          name: QualityFocalLoss
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:
          name: GIoULoss
          loss_weight: 2.0
    # Auxiliary head, only use in training time.
    aux_head:
      name: SimpleConvHead
      num_classes: 10
      input_channel: 192
      feat_channels: 192
      stacked_convs: 4
      strides: [8, 16, 32, 64]
      activation: LeakyReLU
      reg_max: 7

#class_names: &class_names ['Ignore','Pedestrian','People','Bicycle','Car','Van',
#    'Truck','Tricycle','Awning-tricycle','Bus','Motor','Others']  #Please fill in the category names (not include background category)
data:
  train:
    name: CocoDataset
    #class_names: *class_names
    #img_path: TRAIN_IMAGE_FOLDER  #Please fill in train image path
    #img_path: /root/autodl-tmp/VisDrone2019-DET/VisDrone2019-DET-train/images_new
    img_path: /root/autodl-tmp/VisDrone/VisDrone2019-DET-train/images
    #ann_path: TRAIN_XML_FOLDER  #Please fill in train xml path
    #ann_path: /root/autodl-tmp/VisDrone2019-DET/VisDrone2019-DET-train/annotations_new
    ann_path: /root/autodl-tmp/VisDrone/Anno/VisDrone2019-DET_train_coco.json
    input_size: [640,640] #[w,h]
    keep_ratio: True
    pipeline:
      perspective: 0.0
      scale: [0.6, 1.4]
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2
      contrast: [0.8, 1.2]
      saturation: [0.8, 1.2]
      #normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]] # imagenet
      normalize: [[83.82, 85.04, 81.95], [51.93, 51.92, 53.69]]  # visdrone-2019
  val:
    name: CocoDataset
    #class_names: *class_names
    #img_path: VAL_IMAGE_FOLDER #Please fill in val image path
    #img_path: /root/autodl-tmp/VisDrone2019-DET/VisDrone2019-DET-val/images_new
    #img_path: /root/autodl-tmp/VisDrone/VisDrone2019-DET-val/images
    img_path: /root/autodl-tmp/VisDrone/VisDrone2019-DET-test-dev/images
    #ann_path: VAL_XML_FOLDER #Please fill in val xml path
    #ann_path: /root/autodl-tmp/VisDrone2019-DET/VisDrone2019-DET-val/annotations_new
    #ann_path: /root/autodl-tmp/VisDrone/Anno/VisDrone2019-DET_val_coco.json
    ann_path: /root/autodl-tmp/VisDrone/Anno/VisDrone2019-DET_test_coco.json
    input_size: [640,640] #[w,h]
    keep_ratio: True
    pipeline:
      #normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]] # imagenet
      normalize: [[83.82, 85.04, 81.95], [51.93, 51.92, 53.69]]  # visdrone-2019
device:
  gpu_ids: [0] # Set like [0, 1, 2, 3] if you have multi-GPUs
  workers_per_gpu: 8
  batchsize_per_gpu: 16
  precision: 32 # set to 16 to use AMP training
schedule:
  #resume:
  #load_model: /root/autodl-tmp/nanodet/workspace/nanodet_m/model_last.ckpt
  optimizer:
    name: AdamW
    lr: 0.001
    weight_decay: 0.05
  warmup:
    name: linear
    steps: 500
    ratio: 0.0001
  total_epochs: 300
  lr_schedule:
    name: CosineAnnealingLR
    T_max: 300
    eta_min: 0.00005
  val_intervals: 10
grad_clip: 35
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP

log:
  interval: 10


class_names: ['pedestrain', 'people', 'bicycle', 'car', 'van','truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'] 